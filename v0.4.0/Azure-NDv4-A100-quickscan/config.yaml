# SuperBench Config
version: v0.4
superbench:
  enable: null
  monitor:
    enable: true
    sample_duration: 1
    sample_interval: 10
  var:
    default_local_mode: &default_local_mode
      enable: true
      modes:
        - name: local
          proc_num: 8
          prefix: CUDA_VISIBLE_DEVICES={proc_rank}
          parallel: yes
    default_pytorch_mode: &default_pytorch_mode
      enable: true
      modes:
        - name: torch.distributed
          proc_num: 8
          node_num: 1
      frameworks:
        - pytorch
    common_model_config: &common_model_config
      duration: 0
      num_warmup: 64
      num_steps: 2048
      sample_count: 8192
      batch_size: 32
      precision:
        - float32
        - float16
      model_action:
        - train
      pin_memory: yes
  benchmarks:
    kernel-launch:
      <<: *default_local_mode
    gemm-flops:
      <<: *default_local_mode
    nccl-bw:
      enable: true
      modes:
        - name: local
          proc_num: 1
          parallel: no
      parameters:
        ngpus: 8
        minbytes: 8G
        maxbytes: 8G
    ib-loopback:
      enable: true
      modes:
        - name: local
          proc_num: 4
          prefix: PROC_RANK={proc_rank} IB_DEVICES=0,2,4,6 NUMA_NODES=1,0,3,2
          parallel: yes
        - name: local
          proc_num: 4
          prefix: PROC_RANK={proc_rank} IB_DEVICES=1,3,5,7 NUMA_NODES=1,0,3,2
          parallel: yes
      parameters:
        msg_size: 8388608
    cpu-memory-bw-latency:
      enable: true
      modes:
        - name: local
          proc_num: 1
          parallel: no
      parameters:
        tests:
          - bandwidth_matrix
          - latency_matrix
          - max_bandwidth
    mem-bw:
      enable: true
      modes:
        - name: local
          proc_num: 8
          prefix: CUDA_VISIBLE_DEVICES={proc_rank} numactl -N $(({proc_rank}/2))
          parallel: no
    gpt_models:
      <<: *default_pytorch_mode
      models:
        - gpt2-small
        - gpt2-large
      parameters:
        <<: *common_model_config
        batch_size: 8
        seq_len: 224
